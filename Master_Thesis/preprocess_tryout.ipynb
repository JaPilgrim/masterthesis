{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import *\n",
    "from sentence_classifier import SentenceClassifier\n",
    "from tokenizer_class import TokenizerClass\n",
    "from sentence_transformers import SentenceTransformer,util\n",
    "import string\n",
    "from collections import Counter\n",
    "import spacy\n",
    "nlp = spacy.load(\"de_dep_news_trf\")\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "articles=[\"Maschinelles Lernen\", \"Medizin\",\"Wissenschaft\",\"Krankheit\",\"Prävention\",\"Diagnose\",\"Politik\",\"COVID-19\",\"COVID-19-Pandemie\",\"Epidemie\",\"Mykose\",\"Sexuell übertragbare Erkrankung\",\"Infektionskrankheit\",\"Bundestag\",\"Bundesrat\",\"Zeitung\",\"Rundfunk\",\"Verlag\",\"Politisches System der Bundesrepublik Deutschland\",\"Politisches System\",\"Massenmedien\",\"Medienwissenschaft\",\"Publikation\"]\n",
    "# Loop over articles\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=''\n",
    "for name in articles:\n",
    "    print(name)\n",
    "    raw=fetch_rawtext_from_wiki(name)\n",
    "    text=text + raw\n",
    "df=preprocess_classify_wiki_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_rem = df.text.map(remove_stopwords)\n",
    "punct_rem = words_rem.map(lambda x:x.translate(str.maketrans('','',string.punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list=[]\n",
    "for sentence in punct_rem:\n",
    "    doc = nlp(sentence)\n",
    "    sentence_pos =\"\"\n",
    "    for token in doc:\n",
    "        sentence_pos=sentence_pos+\" \"+token.pos_\n",
    "    pos_list.append(sentence_pos)\n",
    "df[\"text\"] = pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pos\"] = pos_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to add remove Numbers & Remove Punctuation here!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_rem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterates over each sentence, applies nlp individually and then adds up string of POS tags of a sentence, than appends it to list. TAKE ABOUT 9 Minutes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(punct_rem[24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pos\"] = pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_pos_list=list(df[df[\"target\"]==True][\"pos\"])\n",
    "noclaim_pos_list=list(df[df[\"target\"]==False][\"pos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_claim=(df[df[\"target\"]==True])\n",
    "dataframe_noclaim=(df[df[\"target\"]==False])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gives most frequent pos combis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_noclaim[\"pos\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " X                                                                      120\n",
      " NUM X                                                                   42\n",
      " NOUN                                                                    27\n",
      " NOUN NOUN NOUN NOUN VERB                                                12\n",
      " NOUN NOUN VERB                                                          10\n",
      "                                                                       ... \n",
      " NOUN NUM AUX PROPN NOUN PROPN X                                          1\n",
      " PROPN VERB ADJ NOUN X                                                    1\n",
      " NUM ADV NUM PROPN PROPN PROPN X                                          1\n",
      " NUM PROPN ADV ADJ X                                                      1\n",
      " SPACE NOUN NOUN PROPN PUNCT ADJ NOUN NOUN ADV ADV ADJ NOUN DET NOUN      1\n",
      "Name: pos, Length: 2877, dtype: int64\n",
      " NUM NOUN VERB ADV NUM ADJ NOUN                                                            3\n",
      " NOUN VERB                                                                                 3\n",
      " NOUN ADV ADJ NOUN NOUN                                                                    2\n",
      " NOUN NOUN NOUN ADV                                                                        2\n",
      " NUM NOUN NUM VERB X NUM ADJ NUM NOUN                                                      2\n",
      "                                                                                          ..\n",
      " NOUN NOUN NOUN NOUN VERB NOUN ADV AUX NOUN ADJ NOUN ADJ PROPN NOUN VERB NOUN NOUN VERB    1\n",
      " ADV NOUN NOUN CCONJ ADJ NOUN NOUN NOUN VERB                                               1\n",
      " ADJ NOUN ADJ NOUN VERB NOUN NOUN NOUN ADJ NOUN NOUN ADJ NOUN                              1\n",
      " ADP ADJ NOUN PROPN NOUN ADV NOUN NOUN ADP ADJ ADJ NOUN ADJ NOUN ADJ NOUN VERB             1\n",
      " NOUN ADP ADV X VERB CCONJ NOUN NOUN ADV NOUN ADJ NOUN                                     1\n",
      "Name: pos, Length: 1061, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataframe_noclaim[\"pos\"].value_counts())\n",
    "print(dataframe_claim[\"pos\"].value_counts())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iterrates throguh noclaim list, and prints out every sentence, whiches pos is matched with any pos of claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=len(noclaim_pos_list)\n",
    "j=0\n",
    "while(j<i):\n",
    "    if(noclaim_pos_list[j] in claim_pos_list):\n",
    "        print(dataframe_noclaim[\"text\"].iloc[j])\n",
    "    j=j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"text\"].iloc[1:5])\n",
    "sentences = list(df[\"text\"].iloc[1:5])\n",
    "paraphrases = util.paraphrase_mining(model,sentences)\n",
    "for paraphrase in paraphrases:\n",
    "    score, i, j = paraphrase\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences[i], sentences[j], score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(df[\"text\"].iloc[1:5])\n",
    "embeddings = model.encode(sentences)\n",
    "for sentence, embedding in zip(sentences, embeddings):\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Embedding:\", embedding)\n",
    "    print(\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentence_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0 (default, Nov 15 2020, 06:25:35) \n[Clang 10.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed4db69b2ad72da59ecb679942dc6ba3d277df9b74703a594d096c49c628851e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
