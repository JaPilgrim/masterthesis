{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jannis/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "import string\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import importlib.metadata as importlib_metadata\n",
    "importlib_metadata.version('tqdm')\n",
    "import spacy\n",
    "from spacy import Language\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "import sqldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package tagsets to /Users/jannis/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/jannis/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /Users/jannis/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package tagsets to /Users/jannis/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('tagsets')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "nltk.download('tagsets')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Code to do initial POS-tagging!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/data_files/all_sentences_class_by_links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_rem = df.text.map(remove_stopwords)\n",
    "punct_rem = words_rem.map(lambda x:x.translate(str.maketrans('','',string.punctuation)))\n",
    "pos_list=[]\n",
    "for sentence in punct_rem:\n",
    "    sentence_pos = get_sentence_pos_list(sentence,nlp)\n",
    "    pos_list.append(sentence_pos)\n",
    "pos_seqings = list(map(lambda x: ' '.join(x),pos_list))\n",
    "df['pos_seq'] = pos_seqings\n",
    "df['pos_list'] = pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/data_files/all_sentences_linklabeled_pos.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining the POS-Union between True / False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/data_files/all_sentences_linklabeled_pos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0.1  Unnamed: 0  \\\n",
      "0                  0           0   \n",
      "1                  1           1   \n",
      "2                  2           2   \n",
      "3                  3           3   \n",
      "4                  4           4   \n",
      "...              ...         ...   \n",
      "460872        460872         677   \n",
      "460873        460873         678   \n",
      "460874        460874         679   \n",
      "460875        460875         680   \n",
      "460876        460876         681   \n",
      "\n",
      "                                                     text  label  \\\n",
      "0       Rudolf Walter Richard Heß  (* 2 April   1894  ...   True   \n",
      "1       Heß war ab 1933 Reichsminister ohne Geschäftsb...   True   \n",
      "2       Öffentlich tat sich Heß als fanatischer Anhäng...   True   \n",
      "3       1933 ernannte ihn Adolf Hitler   zu seinem Ste...   True   \n",
      "4       Am 1 Mai 1941 flog Heß in das Vereinigte König...   True   \n",
      "...                                                   ...    ...   \n",
      "460872  Dieser Missionar macht geltend, daß durch die ...   True   \n",
      "460873  Die Operation wird ja gerade zu einer Zeit aus...   True   \n",
      "460874  Diese Art der intellektuellen Blindheit läßt s...   True   \n",
      "460875   Dem Psychoanalytiker Matthias Franz   zufolge...   True   \n",
      "460876  Die Drohung heiße im Erleben vieler Jungen: „W...   True   \n",
      "\n",
      "                                                  pos_seq  \\\n",
      "0       PROPN PROPN PROPN PROPN SPACE NUM NOUN NUM PRO...   \n",
      "1            PROPN ADP NUM NOUN ADV ADP NUM NOUN ADJ NOUN   \n",
      "2                        ADV VERB PROPN ADJ NOUN NOUN ADV   \n",
      "3                           NUM VERB PROPN PROPN ADJ NOUN   \n",
      "4       NUM NOUN NUM VERB PROPN ADJ ADV SPACE ADJ NOUN...   \n",
      "...                                                   ...   \n",
      "460872  PROPN VERB ADV ADJ NOUN NOUN DET ADV ADJ ADJ N...   \n",
      "460873  NOUN ADV ADV NOUN VERB ADJ ADJ NOUN VERB ADV V...   \n",
      "460874  NOUN ADJ NOUN VERB ADV VERB VERB ADJ ADJ NOUN ...   \n",
      "460875  NOUN PROPN PROPN ADP NOUN ADJ ADV NUM NOUN ADJ...   \n",
      "460876  NOUN NOUN VERB DET ADJ PUNCT SCONJ NOUN NOUN N...   \n",
      "\n",
      "                                                 pos_list pos_union  \n",
      "0       ['PROPN', 'PROPN', 'PROPN', 'PROPN', 'SPACE', ...     False  \n",
      "1       ['PROPN', 'ADP', 'NUM', 'NOUN', 'ADV', 'ADP', ...     False  \n",
      "2       ['ADV', 'VERB', 'PROPN', 'ADJ', 'NOUN', 'NOUN'...     False  \n",
      "3        ['NUM', 'VERB', 'PROPN', 'PROPN', 'ADJ', 'NOUN']      True  \n",
      "4       ['NUM', 'NOUN', 'NUM', 'VERB', 'PROPN', 'ADJ',...     False  \n",
      "...                                                   ...       ...  \n",
      "460872  ['PROPN', 'VERB', 'ADV', 'ADJ', 'NOUN', 'NOUN'...     False  \n",
      "460873  ['NOUN', 'ADV', 'ADV', 'NOUN', 'VERB', 'ADJ', ...     False  \n",
      "460874  ['NOUN', 'ADJ', 'NOUN', 'VERB', 'ADV', 'VERB',...     False  \n",
      "460875  ['NOUN', 'PROPN', 'PROPN', 'ADP', 'NOUN', 'ADJ...     False  \n",
      "460876  ['NOUN', 'NOUN', 'VERB', 'DET', 'ADJ', 'PUNCT'...     False  \n",
      "\n",
      "[460877 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# define a custom aggregation function to calculate the pos_union value\n",
    "def pos_union_func(x):\n",
    "    # count the number of unique labels for this pos_seq\n",
    "    label_count = len(set(x['label']))\n",
    "    # if there is only one unique label, return True\n",
    "    if label_count == 1:\n",
    "        return False\n",
    "    if label_count == 2:\n",
    "        return True\n",
    "    \n",
    "\n",
    "# group by pos_seq and apply the custom aggregation function to calculate pos_union\n",
    "pos_union = df.groupby('pos_seq').apply(pos_union_func).reset_index(name='pos_union')\n",
    "\n",
    "# merge the pos_union back into the original dataframe\n",
    "df_union = df.merge(pos_union, on='pos_seq', how='left')\n",
    "\n",
    "# print the resulting dataframe\n",
    "print(df_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "False    237936\n",
       "True     222941\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_union.value_counts('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos_union\n",
       "False    376785\n",
       "True      83884\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_union.value_counts('pos_union')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>pos_seq</th>\n",
       "      <th>pos_list</th>\n",
       "      <th>pos_union</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Rudolf Walter Richard Heß  (* 2 April   1894  ...</td>\n",
       "      <td>True</td>\n",
       "      <td>PROPN PROPN PROPN PROPN SPACE NUM NOUN NUM PRO...</td>\n",
       "      <td>['PROPN', 'PROPN', 'PROPN', 'PROPN', 'SPACE', ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Heß war ab 1933 Reichsminister ohne Geschäftsb...</td>\n",
       "      <td>True</td>\n",
       "      <td>PROPN ADP NUM NOUN ADV ADP NUM NOUN ADJ NOUN</td>\n",
       "      <td>['PROPN', 'ADP', 'NUM', 'NOUN', 'ADV', 'ADP', ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Öffentlich tat sich Heß als fanatischer Anhäng...</td>\n",
       "      <td>True</td>\n",
       "      <td>ADV VERB PROPN ADJ NOUN NOUN ADV</td>\n",
       "      <td>['ADV', 'VERB', 'PROPN', 'ADJ', 'NOUN', 'NOUN'...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1933 ernannte ihn Adolf Hitler   zu seinem Ste...</td>\n",
       "      <td>True</td>\n",
       "      <td>NUM VERB PROPN PROPN ADJ NOUN</td>\n",
       "      <td>['NUM', 'VERB', 'PROPN', 'PROPN', 'ADJ', 'NOUN']</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Am 1 Mai 1941 flog Heß in das Vereinigte König...</td>\n",
       "      <td>True</td>\n",
       "      <td>NUM NOUN NUM VERB PROPN ADJ ADV SPACE ADJ NOUN...</td>\n",
       "      <td>['NUM', 'NOUN', 'NUM', 'VERB', 'PROPN', 'ADJ',...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  \\\n",
       "0             0           0   \n",
       "1             1           1   \n",
       "2             2           2   \n",
       "3             3           3   \n",
       "4             4           4   \n",
       "\n",
       "                                                text  label  \\\n",
       "0  Rudolf Walter Richard Heß  (* 2 April   1894  ...   True   \n",
       "1  Heß war ab 1933 Reichsminister ohne Geschäftsb...   True   \n",
       "2  Öffentlich tat sich Heß als fanatischer Anhäng...   True   \n",
       "3  1933 ernannte ihn Adolf Hitler   zu seinem Ste...   True   \n",
       "4  Am 1 Mai 1941 flog Heß in das Vereinigte König...   True   \n",
       "\n",
       "                                             pos_seq  \\\n",
       "0  PROPN PROPN PROPN PROPN SPACE NUM NOUN NUM PRO...   \n",
       "1       PROPN ADP NUM NOUN ADV ADP NUM NOUN ADJ NOUN   \n",
       "2                   ADV VERB PROPN ADJ NOUN NOUN ADV   \n",
       "3                      NUM VERB PROPN PROPN ADJ NOUN   \n",
       "4  NUM NOUN NUM VERB PROPN ADJ ADV SPACE ADJ NOUN...   \n",
       "\n",
       "                                            pos_list pos_union  \n",
       "0  ['PROPN', 'PROPN', 'PROPN', 'PROPN', 'SPACE', ...     False  \n",
       "1  ['PROPN', 'ADP', 'NUM', 'NOUN', 'ADV', 'ADP', ...     False  \n",
       "2  ['ADV', 'VERB', 'PROPN', 'ADJ', 'NOUN', 'NOUN'...     False  \n",
       "3   ['NUM', 'VERB', 'PROPN', 'PROPN', 'ADJ', 'NOUN']      True  \n",
       "4  ['NUM', 'NOUN', 'NUM', 'VERB', 'PROPN', 'ADJ',...     False  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_union.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_union.to_csv('../data/data_files/all_sentences_linklabeled_pos_unions.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering for non-overlapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df_union.query('not (label == False and pos_union == True)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "True     222941\n",
       "False    181565\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.value_counts('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos_union\n",
       "False    376785\n",
       "True      27513\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.value_counts('pos_union')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_csv('../data/data_files/all_sentences_posfilter_linklabeled.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess for other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = r\"[^A-Za-z0-9\\s'':;.?()\\[\\]@\\\\\\-/\\$´€`&]+\"\n",
    "df_nan = df_union.copy()\n",
    "df_nan['text'] = df_union['text'].fillna('')\n",
    "df_nan = df_nan.reset_index(drop=True)\n",
    "df_filtered = df_nan[~df_nan['text'].str.contains(regex)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "# group by pos_seq and calculate the union of labels\n",
    "pos_union = df.groupby('pos_seq')['label'].apply(set).apply(lambda x: all(x)).reset_index()\n",
    "\n",
    "# merge the pos_union back into the original dataframe\n",
    "df = df.merge(pos_union, on='pos_seq', how='left')\n",
    "\n",
    "# rename the newly added column to pos_union\n",
    "df = df.rename(columns={'label_x': 'label', 'label_y': 'pos_union'})\n",
    "\n",
    "# print the resulting dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "df_queried.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "union_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT\n",
    "  text,\n",
    "  pos_seq,\n",
    "  label,\n",
    "  (SELECT COUNT(DISTINCT label) FROM df WHERE pos_seq=pos_seq)   AS pos_union\n",
    "FROM\n",
    "  df\n",
    "GROUP BY\n",
    "  text, pos_seq\n",
    "\"\"\"\n",
    "df_union = sqldf.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_union.value_counts('pos_union'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find pos_seq values with both True and False labels\n",
    "pos_seqs = df.groupby('pos_seq')['label'].apply(lambda x: set(x.unique()))\n",
    "mixed_pos_seqs = pos_seqs[pos_seqs.apply(lambda x: True if len(x) > 1 else False)].index\n",
    "\n",
    "# filter dataframe to only include rows with mixed pos_seq values\n",
    "mixed_df = df[df['pos_seq'].isin(mixed_pos_seqs)]\n",
    "\n",
    "# group by pos_seq and filter to only include groups with both True and False labels\n",
    "filtered_groups = mixed_df.groupby('pos_seq').filter(lambda x: set(x['label'].unique()) == set([True, False]))\n",
    "\n",
    "# print out the filtered DataFrame\n",
    "print(filtered_groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify pos_seq values with at least one True and one False target\n",
    "mixed_pos_seqs = df.groupby('pos_seq')['label'].apply(lambda x: set(x.unique())).\\\n",
    "                 apply(lambda x: True if len(x) > 1 and False in x else False).\\\n",
    "                 loc[lambda x: x == True].index\n",
    "\n",
    "# filter original DataFrame to keep only rows with mixed pos_seq values\n",
    "mixed_df = df[df['pos_seq'].isin(mixed_pos_seqs)]\n",
    "\n",
    "# identify rows with target=True\n",
    "true_rows = mixed_df[mixed_df['target'] == True]\n",
    "\n",
    "# identify pos_seq values with at least one True row\n",
    "true_pos_seqs = true_rows['pos_seq'].unique()\n",
    "\n",
    "# filter original DataFrame to remove rows with target=False where a True row exists with the same pos_seq value\n",
    "filtered_df = df[~((df['target'] == False) & (df['pos_seq'].isin(true_pos_seqs)))]\n",
    "\n",
    "# print out the filtered DataFrame\n",
    "print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the dataframe by 'pos_seq'\n",
    "grouped = df.groupby('pos_seq')\n",
    "\n",
    "# loop through each group\n",
    "for pos_seq, group in grouped:\n",
    "    # check if there is at least one 'True' and one 'False' value in the 'label' column\n",
    "    if group['label'].isin([True, False]).all():\n",
    "        # print out the rows with matching 'pos_seq' values\n",
    "        print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value_counts('pos_seq')[25:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_pos_seq(sentence:str,nlp:Language)->str:\n",
    "    \"\"\"Returns the part-of-speech tags of a given sentence as concatenated strings.\n",
    "\n",
    "    Args:\n",
    "        sentence (str): A sentence, preferably cleaned of stopwords & punctuation.\n",
    "        nlp (Language): NLTK language object.\n",
    "\n",
    "    Returns:\n",
    "        str: String of POS tag sequence.\n",
    "    \"\"\"\n",
    "    doc = nlp(sentence)\n",
    "    sentence_pos =\"\"\n",
    "    for token in doc:\n",
    "        sentence_pos=sentence_pos+\" \"+token.pos_\n",
    "    return sentence_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_articles = pd.read_csv('../data/data_files/articles_w_fulltext_standard.csv', sep=',')[['title', 'bytes', 'full_text']]\n",
    "i = 1\n",
    "df = preprocess_classify_wiki_text(all_articles['full_text'].iloc[0])\n",
    "while i < len(all_articles):\n",
    "    working_df = preprocess_classify_wiki_text(all_articles['full_text'].iloc[i])\n",
    "    df = pd.concat([df, working_df])\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "other_pos_list=[]\n",
    "for i in punct_rem:\n",
    "    a = get_sentence_pos_list(i,nlp)\n",
    "    other_pos_list.append(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/data_files/all_sentences_w_pos_union.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boolean mask to select rows where 'label' is TRUE and 'pos_union' is FALSE\n",
    "mask = (df['label'] == True) & (df['pos_union'] == False)\n",
    "\n",
    "# Use boolean indexing to select the rows that match the mask\n",
    "filtered_df = df.loc[mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[df.label == True OR (df.label == FALSE && df.pos_union == TRUE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_pos_list(sentence,nlp:Language)->list[str]:\n",
    "    \"\"\"Returns the part-of-speech tags of a given sentence as list.\n",
    "\n",
    "    Args:\n",
    "        sentence (str): A sentence, preferably cleaned of stopwords & punctuation.\n",
    "        nlp (Language): NLTK language object.\n",
    "\n",
    "    Returns:\n",
    "        list[str]: List of String POS tags.\n",
    "    \"\"\"\n",
    "    \n",
    "    doc = nlp(sentence)\n",
    "    sentence_pos = []\n",
    "    for token in doc:\n",
    "        sentence_pos.append(str(token.pos_))\n",
    "    return sentence_pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list=[]\n",
    "for sentence in punct_rem:\n",
    "    \n",
    "    a = get_sentence_pos(sentence)\n",
    "    pos_list.append(a)\n",
    "df[\"pos\"] = pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pos\"] = pos_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to add remove Numbers & Remove Punctuation here!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_rem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterates over each sentence, applies nlp individually and then adds up string of POS tags of a sentence, than appends it to list. TAKE ABOUT 9 Minutes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pos\"] = pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_pos_list=list(df[df[\"label\"]==True][\"pos\"])\n",
    "noclaim_pos_list=list(df[df[\"label\"]==False][\"pos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_claim=(df[df[\"label\"]==True])\n",
    "dataframe_noclaim=(df[df[\"label\"]==False])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gives most frequent pos combis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_noclaim[\"pos\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataframe_noclaim[\"pos\"].value_counts())\n",
    "print(dataframe_claim[\"pos\"].value_counts())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iterrates throguh noclaim list, and prints out every sentence, whiches pos is matched with any pos of claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=len(noclaim_pos_list)\n",
    "j=0\n",
    "while(j<i):\n",
    "    if(noclaim_pos_list[j] in claim_pos_list):\n",
    "        print(dataframe_noclaim[\"text\"].iloc[j])\n",
    "    j=j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"text\"].iloc[1:5])\n",
    "sentences = list(df[\"text\"].iloc[1:5])\n",
    "paraphrases = util.paraphrase_mining(model,sentences)\n",
    "for paraphrase in paraphrases:\n",
    "    score, i, j = paraphrase\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences[i], sentences[j], score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(df[\"text\"].iloc[1:5])\n",
    "embeddings = model.encode(sentences)\n",
    "for sentence, embedding in zip(sentences, embeddings):\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Embedding:\", embedding)\n",
    "    print(\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mac-tens9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "165501a9f0117b105509117bc31d98a33feff89ebc3b4fa5ccc5352a67b7dfee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
