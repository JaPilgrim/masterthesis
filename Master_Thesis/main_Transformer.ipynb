{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jannis/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/Users/jannis/miniconda3/envs/mac-tens9/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from utils import *\n",
    "from sentence_classifier import SentenceClassifier\n",
    "from tokenizer_class import TokenizerClass\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import DataCollatorWithPadding\n",
    "from evaluate import load\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_articles=pd.read_csv('fulltext_wiki_protected.csv',sep=',')[['title','bytes','full_text']]\n",
    "i=1\n",
    "df=preprocess_classify_wiki_text(all_articles['full_text'].iloc[0])\n",
    "while i<len(all_articles):\n",
    "    working_df=preprocess_classify_wiki_text(all_articles['full_text'].iloc[i])\n",
    "    df=pd.concat([df,working_df])\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_tokenizer = AutoTokenizer.from_pretrained('distilbert-base-german-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_transformer_token(example):\n",
    "    return trans_tokenizer(example['text'], truncation=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 462/462 [00:10<00:00, 43.95ba/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_wiki = wiki_dataset.map(preprocess_transformer_token,batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_tokenized = tokenized_wiki.train_test_split(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=trans_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accuracy = load('accuracy')\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df.sample(50000,random_state=2)\n",
    "tokenizer=TokenizerClass()\n",
    "claim_extract=SentenceClassifier(tokenizer_class=tokenizer,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-german-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-german-cased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-german-cased\", num_labels=2\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Looks like you do not have git-lfs installed, please install. You can install from https://git-lfs.github.com/. Then run `git lfs install` (you only have to do this once).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/mac-tens9/lib/python3.9/site-packages/huggingface_hub/repository.py:585\u001b[0m, in \u001b[0;36mRepository.check_git_versions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 585\u001b[0m     lfs_version \u001b[39m=\u001b[39m run_subprocess(\n\u001b[1;32m    586\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mgit-lfs --version\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlocal_dir\n\u001b[1;32m    587\u001b[0m     )\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mstrip()\n\u001b[1;32m    588\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mac-tens9/lib/python3.9/site-packages/huggingface_hub/utils/_subprocess.py:61\u001b[0m, in \u001b[0;36mrun_subprocess\u001b[0;34m(command, folder, check, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     folder \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(folder)\n\u001b[0;32m---> 61\u001b[0m \u001b[39mreturn\u001b[39;00m subprocess\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m     62\u001b[0m     command,\n\u001b[1;32m     63\u001b[0m     stderr\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mPIPE,\n\u001b[1;32m     64\u001b[0m     stdout\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mPIPE,\n\u001b[1;32m     65\u001b[0m     check\u001b[39m=\u001b[39;49mcheck,\n\u001b[1;32m     66\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     67\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mreplace\u001b[39;49m\u001b[39m\"\u001b[39;49m,  \u001b[39m# if not utf-8, replace char by �\u001b[39;49;00m\n\u001b[1;32m     68\u001b[0m     cwd\u001b[39m=\u001b[39;49mfolder \u001b[39mor\u001b[39;49;00m os\u001b[39m.\u001b[39;49mgetcwd(),\n\u001b[1;32m     69\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m     70\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/mac-tens9/lib/python3.9/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstderr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[0;32m--> 505\u001b[0m \u001b[39mwith\u001b[39;00m Popen(\u001b[39m*\u001b[39;49mpopenargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs) \u001b[39mas\u001b[39;00m process:\n\u001b[1;32m    506\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mac-tens9/lib/python3.9/subprocess.py:951\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[1;32m    949\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m--> 951\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[1;32m    952\u001b[0m                         pass_fds, cwd, env,\n\u001b[1;32m    953\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[1;32m    954\u001b[0m                         p2cread, p2cwrite,\n\u001b[1;32m    955\u001b[0m                         c2pread, c2pwrite,\n\u001b[1;32m    956\u001b[0m                         errread, errwrite,\n\u001b[1;32m    957\u001b[0m                         restore_signals,\n\u001b[1;32m    958\u001b[0m                         gid, gids, uid, umask,\n\u001b[1;32m    959\u001b[0m                         start_new_session)\n\u001b[1;32m    960\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mac-tens9/lib/python3.9/subprocess.py:1821\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1820\u001b[0m         err_msg \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1821\u001b[0m     \u001b[39mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1822\u001b[0m \u001b[39mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'git-lfs'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 14\u001b[0m\n\u001b[1;32m      1\u001b[0m training_args \u001b[39m=\u001b[39m TrainingArguments(\n\u001b[1;32m      2\u001b[0m     output_dir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmy_awesome_model\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     learning_rate\u001b[39m=\u001b[39m\u001b[39m2e-5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     push_to_hub\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 14\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m     15\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m     16\u001b[0m     args\u001b[39m=\u001b[39;49mtraining_args,\n\u001b[1;32m     17\u001b[0m     train_dataset\u001b[39m=\u001b[39;49msplit_tokenized[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     18\u001b[0m     eval_dataset\u001b[39m=\u001b[39;49msplit_tokenized[\u001b[39m'\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     19\u001b[0m     tokenizer\u001b[39m=\u001b[39;49mtrans_tokenizer,\n\u001b[1;32m     20\u001b[0m     data_collator\u001b[39m=\u001b[39;49mdata_collator,\n\u001b[1;32m     21\u001b[0m     compute_metrics\u001b[39m=\u001b[39;49mcompute_metrics,\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     24\u001b[0m trainer\u001b[39m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/miniconda3/envs/mac-tens9/lib/python3.9/site-packages/transformers/trainer.py:497\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39m# Create clone of distant repo and output directory if needed\u001b[39;00m\n\u001b[1;32m    496\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpush_to_hub:\n\u001b[0;32m--> 497\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minit_git_repo(at_init\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    498\u001b[0m     \u001b[39m# In case of pull, we need to make sure every process has the latest.\u001b[39;00m\n\u001b[1;32m    499\u001b[0m     \u001b[39mif\u001b[39;00m is_torch_tpu_available():\n",
      "File \u001b[0;32m~/miniconda3/envs/mac-tens9/lib/python3.9/site-packages/transformers/trainer.py:3332\u001b[0m, in \u001b[0;36mTrainer.init_git_repo\u001b[0;34m(self, at_init)\u001b[0m\n\u001b[1;32m   3330\u001b[0m create_repo(repo_name, token\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mhub_token, private\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mhub_private_repo, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   3331\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3332\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrepo \u001b[39m=\u001b[39m Repository(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49moutput_dir, clone_from\u001b[39m=\u001b[39;49mrepo_name, token\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mhub_token)\n\u001b[1;32m   3333\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m:\n\u001b[1;32m   3334\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39moverwrite_output_dir \u001b[39mand\u001b[39;00m at_init:\n\u001b[1;32m   3335\u001b[0m         \u001b[39m# Try again after wiping output_dir\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mac-tens9/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py:124\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    120\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(\n\u001b[1;32m    121\u001b[0m         fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs\n\u001b[1;32m    122\u001b[0m     )\n\u001b[0;32m--> 124\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/mac-tens9/lib/python3.9/site-packages/huggingface_hub/repository.py:506\u001b[0m, in \u001b[0;36mRepository.__init__\u001b[0;34m(self, local_dir, clone_from, repo_type, token, git_user, git_email, revision, skip_lfs_files, client)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mskip_lfs_files \u001b[39m=\u001b[39m skip_lfs_files\n\u001b[1;32m    504\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient \u001b[39m=\u001b[39m client \u001b[39mif\u001b[39;00m client \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m HfApi()\n\u001b[0;32m--> 506\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_git_versions()\n\u001b[1;32m    508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(token, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    509\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhuggingface_token: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m token\n",
      "File \u001b[0;32m~/miniconda3/envs/mac-tens9/lib/python3.9/site-packages/huggingface_hub/repository.py:589\u001b[0m, in \u001b[0;36mRepository.check_git_versions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    585\u001b[0m     lfs_version \u001b[39m=\u001b[39m run_subprocess(\n\u001b[1;32m    586\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mgit-lfs --version\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlocal_dir\n\u001b[1;32m    587\u001b[0m     )\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mstrip()\n\u001b[1;32m    588\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m--> 589\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    590\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLooks like you do not have git-lfs installed, please install.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    591\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m You can install from https://git-lfs.github.com/.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    592\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m Then run `git lfs install` (you only have to do this once).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    593\u001b[0m     )\n\u001b[1;32m    594\u001b[0m logger\u001b[39m.\u001b[39minfo(git_version \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m lfs_version)\n",
      "\u001b[0;31mOSError\u001b[0m: Looks like you do not have git-lfs installed, please install. You can install from https://git-lfs.github.com/. Then run `git lfs install` (you only have to do this once)."
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=split_tokenized['train'],\n",
    "    eval_dataset=split_tokenized['test'],\n",
    "    tokenizer=trans_tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import create_optimizer\n",
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 16\n",
    "num_epochs = 5\n",
    "batches_per_epoch = len(claim_extract.train_df) // batch_size\n",
    "total_train_steps = int(batches_per_epoch * num_epochs)\n",
    "optimizer, schedule = create_optimizer(init_lr=2e-5, num_warmup_steps=0, num_train_steps=total_train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 32, 32)            3033728   \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 256)               295936    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,329,921\n",
      "Trainable params: 3,329,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(layers.Embedding(claim_extract.tokenizer_class.num_unique_words, 32, input_length=32))\n",
    "# The layer will take as input an integer matrix of size (batch, input_length),\n",
    "# and the largest integer (i.e. word index) in the input should be no larger than num_words (vocabulary size).\n",
    "# Now model.output_shape is (None, input_length, 32), where `None` is the batch dimension.\n",
    "model.add(layers.LSTM(256, dropout=0.1))\n",
    "model.add(layers.Dense(1, activation=\"relu\"))\n",
    "#TODO try out others than sigmoid\n",
    "#min 2nd layer or more\n",
    "model.summary()\n",
    "loss = keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "optim = keras.optimizers.Adam(learning_rate=0.001)\n",
    "metrics = [\"accuracy\"]\n",
    "model.compile(loss=loss, optimizer=optim, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 32, 32)            3033728   \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 256)               295936    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,329,921\n",
      "Trainable params: 3,329,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 16:51:07.295607: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-13 16:51:07.612880: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-13 16:51:07.924882: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668/668 [==============================] - ETA: 0s - loss: 0.7126 - accuracy: 0.5292"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 16:51:32.177107: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-13 16:51:32.261231: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668/668 [==============================] - 27s 38ms/step - loss: 0.7126 - accuracy: 0.5292 - val_loss: 0.6555 - val_accuracy: 0.6099\n",
      "Epoch 2/20\n",
      "668/668 [==============================] - 21s 31ms/step - loss: 0.6201 - accuracy: 0.6778 - val_loss: 0.7975 - val_accuracy: 0.5813\n",
      "Epoch 3/20\n",
      "668/668 [==============================] - 19s 29ms/step - loss: 0.4059 - accuracy: 0.8469 - val_loss: 1.0244 - val_accuracy: 0.6049\n",
      "Epoch 3: early stopping\n"
     ]
    }
   ],
   "source": [
    "df_train=df.sample(50000,random_state=2)\n",
    "tokenizer=TokenizerClass()\n",
    "claim_extract=SentenceClassifier(tokenizer_class=tokenizer,model=model)\n",
    "claim_extract.preprocess_train_val(df_train)\n",
    "claim_extract.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 16:52:18.782000: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-13 16:52:18.848060: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 58ms/step\n"
     ]
    }
   ],
   "source": [
    "annotated=pd.read_csv('FullAnnotated1.csv',sep=';',dtype={'sentence':'str'})\n",
    "annotated=annotated[annotated['to_exclude']==0]\n",
    "annotated['prediction']=claim_extract.predict_target(annotated['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a,b=plot_compute_AUC(annotated['is_claim'],  annotated['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute 'any'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m \u001b[39mimport\u001b[39;00m metrics\n\u001b[0;32m----> 2\u001b[0m fpr, tpr, _ \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39;49mroc_curve(annotated[\u001b[39m'\u001b[39;49m\u001b[39mis_claim\u001b[39;49m\u001b[39m'\u001b[39;49m],  annotated[\u001b[39m'\u001b[39;49m\u001b[39mprediction\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      3\u001b[0m auc \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39mroc_auc_score(annotated[\u001b[39m'\u001b[39m\u001b[39mis_claim\u001b[39m\u001b[39m'\u001b[39m],  annotated[\u001b[39m'\u001b[39m\u001b[39mprediction\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[39m#create ROC curve\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mac-tens9/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:992\u001b[0m, in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mroc_curve\u001b[39m(\n\u001b[1;32m    905\u001b[0m     y_true, y_score, \u001b[39m*\u001b[39m, pos_label\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, drop_intermediate\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    906\u001b[0m ):\n\u001b[1;32m    907\u001b[0m     \u001b[39m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[1;32m    908\u001b[0m \n\u001b[1;32m    909\u001b[0m \u001b[39m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[39m    array([1.8 , 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 992\u001b[0m     fps, tps, thresholds \u001b[39m=\u001b[39m _binary_clf_curve(\n\u001b[1;32m    993\u001b[0m         y_true, y_score, pos_label\u001b[39m=\u001b[39;49mpos_label, sample_weight\u001b[39m=\u001b[39;49msample_weight\n\u001b[1;32m    994\u001b[0m     )\n\u001b[1;32m    996\u001b[0m     \u001b[39m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[1;32m    997\u001b[0m     \u001b[39m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[1;32m    998\u001b[0m     \u001b[39m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1003\u001b[0m     \u001b[39m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m     \u001b[39m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m     \u001b[39mif\u001b[39;00m drop_intermediate \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(fps) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mac-tens9/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:755\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    753\u001b[0m y_score \u001b[39m=\u001b[39m column_or_1d(y_score)\n\u001b[1;32m    754\u001b[0m assert_all_finite(y_true)\n\u001b[0;32m--> 755\u001b[0m assert_all_finite(y_score)\n\u001b[1;32m    757\u001b[0m \u001b[39m# Filter out zero-weighted samples, as they should not impact the result\u001b[39;00m\n\u001b[1;32m    758\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mac-tens9/lib/python3.9/site-packages/sklearn/utils/validation.py:190\u001b[0m, in \u001b[0;36massert_all_finite\u001b[0;34m(X, allow_nan, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39massert_all_finite\u001b[39m(\n\u001b[1;32m    165\u001b[0m     X,\n\u001b[1;32m    166\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m     input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    170\u001b[0m ):\n\u001b[1;32m    171\u001b[0m     \u001b[39m\"\"\"Throw a ValueError if X contains NaN or infinity.\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \n\u001b[1;32m    173\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[39m        documentation.\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m     _assert_all_finite(\n\u001b[1;32m    191\u001b[0m         X\u001b[39m.\u001b[39;49mdata \u001b[39mif\u001b[39;49;00m sp\u001b[39m.\u001b[39;49missparse(X) \u001b[39melse\u001b[39;49;00m X,\n\u001b[1;32m    192\u001b[0m         allow_nan\u001b[39m=\u001b[39;49mallow_nan,\n\u001b[1;32m    193\u001b[0m         estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    194\u001b[0m         input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    195\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/mac-tens9/lib/python3.9/site-packages/sklearn/utils/validation.py:110\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan:\n\u001b[0;32m--> 110\u001b[0m     \u001b[39mif\u001b[39;00m _object_dtype_isnan(X)\u001b[39m.\u001b[39;49many():\n\u001b[1;32m    111\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInput contains NaN\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    113\u001b[0m \u001b[39m# We need only consider float arrays, hence can early return for all else.\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bool' object has no attribute 'any'"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, _ = metrics.roc_curve(annotated['is_claim'],  annotated['prediction'])\n",
    "auc = metrics.roc_auc_score(annotated['is_claim'],  annotated['prediction'])\n",
    "#create ROC curve\n",
    "plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Until autorun till here!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUntil autorun till here!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Until autorun till here!"
     ]
    }
   ],
   "source": [
    "raise KeyboardInterrupt(\"Until autorun till here!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0                                           sentence  is_claim  \\\n",
      "0             0  Ärger über Gasmasken-Eklat Samstag, 1 Juli, 12...         1   \n",
      "1             1  Dabei hatte die Projektleitung eigentlich ein ...         0   \n",
      "2             2  Trotz der beiden Bike-Lanes ist der Verkehr au...         1   \n",
      "3             3  Interessant ist, dass es der Civey-Umfrage zuf...         1   \n",
      "4             4  Die Salzburger Festspiele aber haben sich zumi...         0   \n",
      "..          ...                                                ...       ...   \n",
      "100         100  Auf manchen Friedhöfen gebe es eine überdachte...         0   \n",
      "101         101  Sie schlagen mit ihren Gummiknüppeln auf die M...         1   \n",
      "102         102  Anfang Mai wähnte sich die nationalpopulistisc...         1   \n",
      "104         104  Der Inhalt der Mails, die dem britischen Morni...         1   \n",
      "105         105                           ZEIT ONLINE: Inwiefern\\?         0   \n",
      "\n",
      "     to_exclude      prediction  \n",
      "0             0  [0.0010990133]  \n",
      "1             0  [0.0026316766]  \n",
      "2             0    [0.69326824]  \n",
      "3             0  [0.0024009256]  \n",
      "4             0   [0.001974012]  \n",
      "..          ...             ...  \n",
      "100           0     [0.6529557]  \n",
      "101           0  [0.0033301108]  \n",
      "102           0  [0.0033770262]  \n",
      "104           0    [0.38587052]  \n",
      "105           0    [0.15224144]  \n",
      "\n",
      "[97 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(annotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fang_text=fetch_from_fangcovid_local(5,10)\n",
    "#fang_pre=preprocess_text(fang_text)\n",
    "df_fang=pd.DataFrame()\n",
    "df_fang[\"text\"]=split_text(fang_text)\n",
    "df_fang[\"prediction\"]=claim_extract.predict_target(df_fang[\"text\"])\n",
    "\n",
    "# df_fang[\"tokenized\"]=tokenizer.texts_to_sequences(df_fang[\"sentence\"])\n",
    "# fang_padded = pad_sequences(df_fang[\"tokenized\"], maxlen=32, padding=\"post\", truncating=\"post\")\n",
    "# df_fang[\"predictions\"]=model.predict(fang_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = articles+articles_strict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_strict=['Wiesentalbrücke','Mammut (Gattung)','Riemannsche Vermutung','Reichstag zu Augsburg','Deutsch-Französischer Krieg','Kantonsspital Winterthur','Femizid','Nicht-zufällige Segregation von Chromosomen','Beryllium','Massenaussterben','Covid-19','Pandemie','Sex','Homosexualität','OG Keemo','Conchita Wurst','Hochschule für Medien, Kommunikation und Wirtschaft','Europäische Union','Biographie','Donald Trump','Angstzustände','Doktortitel','BAHN-BKK']\n",
    "articles=articles+articles_strict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles=[\"Maschinelles Lernen\", \"Medizin\",\"Wissenschaft\",\"Krankheit\",\"Prävention\",\"Diagnose\",\"Politik\",\"COVID-19\",\"COVID-19-Pandemie\",\"Epidemie\",\"Mykose\",\"Sexuell übertragbare Erkrankung\",\"Infektionskrankheit\",\"Bundestag\",\"Bundesrat\",\"Zeitung\",\"Rundfunk\",\"Verlag\",\"Politisches System der Bundesrepublik Deutschland\",\"Politisches System\",\"Massenmedien\",\"Medienwissenschaft\",\"Publikation\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiesentalbrücke\n",
      "Mammut (Gattung)\n",
      "Riemannsche Vermutung\n",
      "Reichstag zu Augsburg\n",
      "Deutsch-Französischer Krieg\n",
      "Kantonsspital Winterthur\n",
      "Femizid\n",
      "Nicht-zufällige Segregation von Chromosomen\n",
      "Beryllium\n",
      "Massenaussterben\n",
      "Covid-19\n",
      "Pandemie\n",
      "Sex\n",
      "Homosexualität\n",
      "OG Keemo\n",
      "Conchita Wurst\n",
      "Hochschule für Medien, Kommunikation und Wirtschaft\n",
      "Europäische Union\n",
      "Biographie\n",
      "Donald Trump\n",
      "Angstzustände\n",
      "Doktortitel\n",
      "BAHN-BKK\n"
     ]
    }
   ],
   "source": [
    "# Loop over articles\n",
    "\n",
    "text=''\n",
    "for name in articles:\n",
    "    print(name)\n",
    "    raw=fetch_rawtext_from_wiki(name)\n",
    "    text=text + raw\n",
    "df=preprocess_classify_wiki_text(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline, if \"claims\" is free text of all labeled claims \n",
    "\n",
    "split_claims=split_text(claims)\n",
    "df_claim =pd.DataFrame()\n",
    "df_claim[\"text\"]= split_claims\n",
    "df_claim=df_claim.assign(target=True)\n",
    "df=df.loc[df[\"target\"]==False]\n",
    "df=pd.concat([df,df_claim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m df_minority \u001b[39m=\u001b[39m df[df\u001b[39m.\u001b[39mtarget\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[39m# Downsample majority class\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m df_majority_downsampled \u001b[39m=\u001b[39m resample(df_majority, \n\u001b[1;32m      7\u001b[0m                                  replace\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,    \u001b[39m# sample without replacement\u001b[39;00m\n\u001b[1;32m      8\u001b[0m                                  n_samples\u001b[39m=\u001b[39m\u001b[39m2451\u001b[39m,     \u001b[39m# to match minority class\u001b[39;00m\n\u001b[1;32m      9\u001b[0m                                  random_state\u001b[39m=\u001b[39m\u001b[39m123\u001b[39m) \u001b[39m# reproducible results\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m# Combine minority class with downsampled majority class\u001b[39;00m\n\u001b[1;32m     12\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([df_majority_downsampled, df_minority])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'resample' is not defined"
     ]
    }
   ],
   "source": [
    "## Re-Balanced Class Sets\n",
    "df_majority = df[df.target==0]\n",
    "df_minority = df[df.target==1]\n",
    " \n",
    "# Downsample majority class\n",
    "df_majority_downsampled = random.sample(df_majority, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=2451,     # to match minority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine minority class with downsampled majority class\n",
    "df = pd.concat([df_majority_downsampled, df_minority])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fang_text=fetch_from_fangcovid_local(5,10)\n",
    "#fang_pre=preprocess_text(fang_text)\n",
    "df_fang=pd.DataFrame()\n",
    "df_fang[\"sentence\"]=split_text(fang_text)\n",
    "df_fang[\"tokenized\"]=tokenizer.texts_to_sequences(df_fang[\"sentence\"])\n",
    "fang_padded = pad_sequences(df_fang[\"tokenized\"], maxlen=32, padding=\"post\", truncating=\"post\")\n",
    "df_fang[\"predictions\"]=model.predict(fang_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fang[\"predictions\"]=model.predict(fang_padded)\n",
    "\n",
    "print(df_fang.sort_values(\"predictions\"))\n",
    "os.chdir(\"/Users/jannis/Desktop/fang-covid-main\")\n",
    "df_fang=df_fang[['predictions','sentence']]\n",
    "df_fang.to_csv(\"results7.csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_count={}\n",
    "claims=\" \"\n",
    "os.chdir(\"/Users/jannis/Desktop/x-fact-main/data/x-fact\")\n",
    "with open(\"train.all.tsv\", 'r') as fp:\n",
    "    for line in fp:\n",
    "        arr = line.strip().split('\\t')\n",
    "        lang = arr[1].lower()\n",
    "        site = arr[2].lower()\n",
    "        domain = (lang, site)\n",
    "        \n",
    "\n",
    "        if domain not in label_count:\n",
    "                label_count[domain] = {}\n",
    "        if arr[0] == 'de':\n",
    "            claims = claims + arr[3]\n",
    "            print(arr[3])\n",
    "            \n",
    "\n",
    "        label = arr[-1].lower()\n",
    "\n",
    "        if label not in label_count[domain]:\n",
    "            label_count[domain][label] = 0\n",
    "        label_count[domain][label] +=1\n",
    "\n",
    "\n",
    "\n",
    "# new_map = {}\n",
    "# for key in label_count.keys():\n",
    "#     new_map[key] = {}\n",
    "#     counts = label_count[key]\n",
    "\n",
    "#     total = 0\n",
    "#     for k, v in counts.items():\n",
    "#         total += v\n",
    "\n",
    "#     for k,v in counts.items():\n",
    "#         new_map[key][k] = float(v)/total\n",
    "\n",
    "\n",
    "# print(new_map)\n",
    "\n",
    "# total = 0\n",
    "# count = 0\n",
    "# for key in new_map.keys():\n",
    "#     counts = new_map[key]\n",
    "#     take = True\n",
    "#     for k, v in counts.items():\n",
    "#         if v > 0.7:\n",
    "#             take = False\n",
    "\n",
    "#     if take:\n",
    "#         print(key)\n",
    "#         count +=1\n",
    "#         for k, v in label_count[key].items():\n",
    "#             total += v\n",
    "\n",
    "# print(total)\n",
    "# print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"https://raw.githubusercontent.com/justusmattern/fang-covid/main/articles/20000.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"mlsum\", \"de\")\n",
    "df_json=pd.read_json(dataset[\"train\"])\n",
    "claim=\" \"\n",
    "i=0\n",
    "while i<10000:\n",
    "    claim=claim+dataset[\"train\"][\"summary\"][randint(0,220000)]\n",
    "    i=+1\n",
    "array=dataset[\"train\"][\"summary\"][:10000]\n",
    "s=\" \".join(array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=German()\n",
    "doc=nlp(text)\n",
    "nlp.add_pipe('sentencizer')\n",
    "sents=list(doc.sents)\n",
    "print(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    nlp = spacy.load(\"de_core_news_md\")\n",
    "    doc = nlp(sentences[0])\n",
    "    print(doc.text)\n",
    "    for token in doc:\n",
    "        print(token.text, token.pos_, token.dep_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "165501a9f0117b105509117bc31d98a33feff89ebc3b4fa5ccc5352a67b7dfee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
