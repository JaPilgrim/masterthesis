{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jannis/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import ast\n",
    "sys.path.append(\"..\")\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "import string\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import importlib.metadata as importlib_metadata\n",
    "\n",
    "importlib_metadata.version('tqdm')\n",
    "import spacy\n",
    "from spacy import Language\n",
    "\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "import sqldf\n",
    "import Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'resolved_sentence_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/mac-tens9/lib/python3.9/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/mac-tens9/lib/python3.9/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/mac-tens9/lib/python3.9/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'resolved_sentence_list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39m# Drop rows with indexes 478 and 802\u001b[39;00m\n\u001b[1;32m      3\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39msentence_list\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39msentence_list\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\n\u001b[1;32m      4\u001b[0m     ast\u001b[39m.\u001b[39mliteral_eval)\n\u001b[0;32m----> 5\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mresolved_sentence_list\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mresolved_sentence_list\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mapply(\n\u001b[1;32m      6\u001b[0m     ast\u001b[39m.\u001b[39mliteral_eval)\n\u001b[1;32m      7\u001b[0m res_cut \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mresolved_sentence_list[\u001b[39m133\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m      8\u001b[0m sen_cut \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39msentence_list[\u001b[39m133\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/mac-tens9/lib/python3.9/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda3/envs/mac-tens9/lib/python3.9/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'resolved_sentence_list'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/2_articles_labeled_cleaned.csv', nrows=140)\n",
    "# Drop rows with indexes 478 and 802\n",
    "df['sentence_list'] = df['sentence_list'].apply(\n",
    "    ast.literal_eval)\n",
    "df['resolved_sentence_list'] = df['resolved_sentence_list'].apply(\n",
    "    ast.literal_eval)\n",
    "res_cut = df.resolved_sentence_list[133][-1]\n",
    "sen_cut = df.sentence_list[133][-1]\n",
    "print(sen_cut)\n",
    "print(res_cut)\n",
    "# Reset the indexes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/all_articles_resolved_truth_cleaned_new.csv',nrows=50)\n",
    "df['sentence_list'] = df['sentence_list'].apply(\n",
    "    ast.literal_eval)\n",
    "df['resolved_sentence_list'] = df['resolved_sentence_list'].apply(\n",
    "    ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     \n",
       "1     \n",
       "2     \n",
       "3     \n",
       "4     \n",
       "5     \n",
       "6     \n",
       "7     \n",
       "8     \n",
       "9     \n",
       "10    \n",
       "11    \n",
       "12    \n",
       "13    \n",
       "14    \n",
       "15    \n",
       "16    \n",
       "17    \n",
       "18    \n",
       "19    \n",
       "20    \n",
       "21    \n",
       "22    \n",
       "23    \n",
       "24    \n",
       "25    \n",
       "26    \n",
       "27    \n",
       "28    \n",
       "29    \n",
       "30    \n",
       "31    \n",
       "32    \n",
       "33    \n",
       "34    \n",
       "35    \n",
       "36    \n",
       "37    \n",
       "38    \n",
       "39    \n",
       "40    \n",
       "41    \n",
       "42    \n",
       "43    \n",
       "44    \n",
       "45    \n",
       "46    \n",
       "47    \n",
       "48    \n",
       "49    \n",
       "Name: resolved_sentence_list, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(words_rem[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package tagsets to /Users/jannis/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/jannis/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /Users/jannis/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package tagsets to /Users/jannis/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('tagsets')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'title', 'bytes', 'resolved_text_list',\n",
      "       'cleaned_article_text', 'sub_texts', 'resolved_sentence_list',\n",
      "       'sentence_list', 'quot_truth_list', 'link_truth_list',\n",
      "       'linkname_truth_list', 'pos_seq', 'pos_list'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/all_articles_resolved_truth_cleaned_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_sentence_list = df.sentence_list\n",
    "article_resolved_sentence_list = df.resolved_sentence_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sentence_list = []\n",
    "for sentence_list in article_sentence_list:\n",
    "    words_rem = [remove_stopwords(sentence) for sentence in sentence_list]\n",
    "    punct_rem = [sentence.translate(str.maketrans('', '', string.punctuation)) for sentence in words_rem]\n",
    "    pos_list = []\n",
    "    for sentence in punct_rem:\n",
    "        sentence_pos = get_sentence_pos_str(sentence, nlp)\n",
    "        pos_list.append(sentence_pos)\n",
    "    pos_sentence_list.append(pos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sentence_list = []\n",
    "for i,sentence_list in enumerate(article_sentence_list):\n",
    "    words_rem = [remove_stopwords(sentence) for sentence in sentence_list]\n",
    "    punct_rem = [\n",
    "        sentence.translate(str.maketrans('', '', string.punctuation)) for sentence in words_rem\n",
    "    ]\n",
    "    pos_list = []\n",
    "    for sentence in punct_rem:\n",
    "        sentence_pos = get_sentence_pos_str(sentence, nlp)\n",
    "        pos_list.append(sentence_pos)\n",
    "    pos_sentence_list.append(pos_list)\n",
    "    if(len(pos_list)!=len(sentence_list)):\n",
    "        print(i)\n",
    "\n",
    "pos_resolved_sentence_list = []\n",
    "for i,sentence_list in enumerate(article_resolved_sentence_list):\n",
    "    words_rem = [remove_stopwords(sentence) for sentence in sentence_list]\n",
    "    punct_rem = [\n",
    "        sentence.translate(str.maketrans('', '', string.punctuation)) for sentence in words_rem\n",
    "    ]\n",
    "    pos_list = []\n",
    "    for sentence in punct_rem:\n",
    "        sentence_pos = get_sentence_pos_str(sentence, nlp)\n",
    "        pos_list.append(sentence_pos)\n",
    "    pos_resolved_sentence_list.append(pos_list)\n",
    "    if(len(pos_list)!=len(sentence_list)):\n",
    "        print(i)\n",
    "df['pos_sentence_list']=pos_sentence_list\n",
    "df['pos_resolved_sentence_list']=pos_resolved_sentence_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>bytes</th>\n",
       "      <th>resolved_text_list</th>\n",
       "      <th>cleaned_article_text</th>\n",
       "      <th>sub_texts</th>\n",
       "      <th>resolved_sentence_list</th>\n",
       "      <th>sentence_list</th>\n",
       "      <th>quot_truth_list</th>\n",
       "      <th>link_truth_list</th>\n",
       "      <th>linkname_truth_list</th>\n",
       "      <th>pos_seq</th>\n",
       "      <th>pos_list</th>\n",
       "      <th>pos_sentence_list</th>\n",
       "      <th>pos_resolved_sentence_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Rudolf Heß</td>\n",
       "      <td>86302</td>\n",
       "      <td>Rudolf Walter Richard Heß    26 April 1894 in ...</td>\n",
       "      <td>Rudolf Walter Richard Heß   26 April 1894 in A...</td>\n",
       "      <td>Rudolf Walter Richard Heß [] (* 26 April== 189...</td>\n",
       "      <td>[Rudolf Walter Richard Heß    26 April 1894 in...</td>\n",
       "      <td>[Rudolf Walter Richard Heß   26 April 1894 in ...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[ PROPN PROPN PROPN PROPN NUM NOUN NUM ADV ADJ...</td>\n",
       "      <td>[ PROPN PROPN PROPN PROPN NUM NOUN NUM PRON SP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Popo</td>\n",
       "      <td>805</td>\n",
       "      <td>Popo ist Siehe auch :</td>\n",
       "      <td>Popo ist Siehe auch:</td>\n",
       "      <td>Popo ist \\nSiehe auch:\\n</td>\n",
       "      <td>[Popo ist Siehe auch : ]</td>\n",
       "      <td>[Popo ist Siehe auch:]</td>\n",
       "      <td>[False]</td>\n",
       "      <td>[False]</td>\n",
       "      <td>[False]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[ NOUN VERB ADV]</td>\n",
       "      <td>[ NOUN VERB]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Kanake</td>\n",
       "      <td>309</td>\n",
       "      <td>Kanake steht für : Siehe auch :</td>\n",
       "      <td>Kanake steht für: Siehe auch:</td>\n",
       "      <td>Kanake steht für:\\n\\nSiehe auch:\\n</td>\n",
       "      <td>[Kanake steht für : Siehe auch : ]</td>\n",
       "      <td>[Kanake steht für: Siehe auch:]</td>\n",
       "      <td>[False]</td>\n",
       "      <td>[False]</td>\n",
       "      <td>[False]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[ PROPN VERB ADP VERB ADV]</td>\n",
       "      <td>[ PROPN VERB SPACE VERB]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Bitch</td>\n",
       "      <td>5369</td>\n",
       "      <td>Bitch ist ein Begriff aus dem Englischen , der...</td>\n",
       "      <td>Bitch ist ein Begriff aus dem Englischen, der ...</td>\n",
       "      <td>Bitch  ist ein Begriff aus dem Englischen, der...</td>\n",
       "      <td>[Bitch ist ein Begriff aus dem Englischen , de...</td>\n",
       "      <td>[Bitch ist ein Begriff aus dem Englischen, der...</td>\n",
       "      <td>[False, False, False, True, True, False, True,...</td>\n",
       "      <td>[True, True, True, True, True, False, True, Tr...</td>\n",
       "      <td>[True, True, True, True, True, False, True, Tr...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[ PROPN NOUN ADJ ADJ NOUN NOUN VERB NOUN ADJ N...</td>\n",
       "      <td>[ PROPN NOUN ADJ SPACE ADJ NOUN NOUN VERB NOUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Fisting</td>\n",
       "      <td>7432</td>\n",
       "      <td>Faustverkehr engl Fisting , von fist „ Faust “...</td>\n",
       "      <td>Faustverkehr engl Fisting, von fist „Faust“ be...</td>\n",
       "      <td>Faustverkehr (engl== Fisting, von fist „Faust“...</td>\n",
       "      <td>[Faustverkehr engl Fisting , von fist „ Faust ...</td>\n",
       "      <td>[Faustverkehr engl Fisting, von fist „Faust“ b...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[True, False, False, False, True, False, True,...</td>\n",
       "      <td>[True, False, False, True, True, False, True, ...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[ NOUN PROPN PROPN PROPN PUNCT NOUN PUNCT CCON...</td>\n",
       "      <td>[ NOUN PROPN PROPN SPACE PROPN PUNCT NOUN PUNC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       title  bytes  \\\n",
       "0           0  Rudolf Heß  86302   \n",
       "1           1        Popo    805   \n",
       "2           2      Kanake    309   \n",
       "3           3       Bitch   5369   \n",
       "4           4     Fisting   7432   \n",
       "\n",
       "                                  resolved_text_list  \\\n",
       "0  Rudolf Walter Richard Heß    26 April 1894 in ...   \n",
       "1                             Popo ist Siehe auch :    \n",
       "2                   Kanake steht für : Siehe auch :    \n",
       "3  Bitch ist ein Begriff aus dem Englischen , der...   \n",
       "4  Faustverkehr engl Fisting , von fist „ Faust “...   \n",
       "\n",
       "                                cleaned_article_text  \\\n",
       "0  Rudolf Walter Richard Heß   26 April 1894 in A...   \n",
       "1                               Popo ist Siehe auch:   \n",
       "2                      Kanake steht für: Siehe auch:   \n",
       "3  Bitch ist ein Begriff aus dem Englischen, der ...   \n",
       "4  Faustverkehr engl Fisting, von fist „Faust“ be...   \n",
       "\n",
       "                                           sub_texts  \\\n",
       "0  Rudolf Walter Richard Heß [] (* 26 April== 189...   \n",
       "1                           Popo ist \\nSiehe auch:\\n   \n",
       "2                 Kanake steht für:\\n\\nSiehe auch:\\n   \n",
       "3  Bitch  ist ein Begriff aus dem Englischen, der...   \n",
       "4  Faustverkehr (engl== Fisting, von fist „Faust“...   \n",
       "\n",
       "                              resolved_sentence_list  \\\n",
       "0  [Rudolf Walter Richard Heß    26 April 1894 in...   \n",
       "1                           [Popo ist Siehe auch : ]   \n",
       "2                 [Kanake steht für : Siehe auch : ]   \n",
       "3  [Bitch ist ein Begriff aus dem Englischen , de...   \n",
       "4  [Faustverkehr engl Fisting , von fist „ Faust ...   \n",
       "\n",
       "                                       sentence_list  \\\n",
       "0  [Rudolf Walter Richard Heß   26 April 1894 in ...   \n",
       "1                             [Popo ist Siehe auch:]   \n",
       "2                    [Kanake steht für: Siehe auch:]   \n",
       "3  [Bitch ist ein Begriff aus dem Englischen, der...   \n",
       "4  [Faustverkehr engl Fisting, von fist „Faust“ b...   \n",
       "\n",
       "                                     quot_truth_list  \\\n",
       "0  [False, False, False, False, False, False, Fal...   \n",
       "1                                            [False]   \n",
       "2                                            [False]   \n",
       "3  [False, False, False, True, True, False, True,...   \n",
       "4  [False, False, False, False, False, False, Fal...   \n",
       "\n",
       "                                     link_truth_list  \\\n",
       "0  [True, True, True, True, True, True, True, Tru...   \n",
       "1                                            [False]   \n",
       "2                                            [False]   \n",
       "3  [True, True, True, True, True, False, True, Tr...   \n",
       "4  [True, False, False, False, True, False, True,...   \n",
       "\n",
       "                                 linkname_truth_list pos_seq pos_list  \\\n",
       "0  [True, True, True, True, True, True, True, Tru...               []   \n",
       "1                                            [False]               []   \n",
       "2                                            [False]               []   \n",
       "3  [True, True, True, True, True, False, True, Tr...               []   \n",
       "4  [True, False, False, True, True, False, True, ...               []   \n",
       "\n",
       "                                   pos_sentence_list  \\\n",
       "0  [ PROPN PROPN PROPN PROPN NUM NOUN NUM ADV ADJ...   \n",
       "1                                   [ NOUN VERB ADV]   \n",
       "2                         [ PROPN VERB ADP VERB ADV]   \n",
       "3  [ PROPN NOUN ADJ ADJ NOUN NOUN VERB NOUN ADJ N...   \n",
       "4  [ NOUN PROPN PROPN PROPN PUNCT NOUN PUNCT CCON...   \n",
       "\n",
       "                          pos_resolved_sentence_list  \n",
       "0  [ PROPN PROPN PROPN PROPN NUM NOUN NUM PRON SP...  \n",
       "1                                       [ NOUN VERB]  \n",
       "2                           [ PROPN VERB SPACE VERB]  \n",
       "3  [ PROPN NOUN ADJ SPACE ADJ NOUN NOUN VERB NOUN...  \n",
       "4  [ NOUN PROPN PROPN SPACE PROPN PUNCT NOUN PUNC...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'title', 'bytes', 'sub_texts', 'sentence_list',\n",
      "       'quot_truth_list', 'link_truth_list', 'linkname_truth_list'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "all_article_list_full = pd.read_csv('../data/all_articles_resolved_truth_cleaned.csv', nrows=13)\n",
    "print(all_article_list_full.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_article_list_full['sentence_list'] = df['sentence_list'].apply(ast.literal_eval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mac-tens9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
